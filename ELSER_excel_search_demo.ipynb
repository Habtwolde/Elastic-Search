{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0769020",
   "metadata": {},
   "source": [
    "# ELSER Excel → Elasticsearch (Semantic Search) — One-Click Notebook\n",
    "\n",
    "This notebook does two things:\n",
    "1. **(Optional)** Ingest an Excel/CSV file into an Elasticsearch index using the **ELSER** ingest pipeline (`ml.tokens`).\n",
    "2. **Run a semantic search** over that index and save a **client-friendly HTML report** — so you can reopen and show results **without rerunning** a live query.\n",
    "\n",
    "> **Tip:** Set `RUN_INGEST=False` if your index already contains the Excel data (to avoid reindexing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca603f8d",
   "metadata": {},
   "source": [
    "#### 0) Install Python packages (first run only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42820e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If these are already installed in your venv, you can skip this cell.\n",
    "# In VS Code/Jupyter on your machine, uncomment the next line and run once.\n",
    "#!pip install elasticsearch==8.14.0 \"urllib3<2\" pandas openpyxl python-dateutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9703ab2",
   "metadata": {},
   "source": [
    "#### 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371cfcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser as dtparser\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "# ---- Elasticsearch / ELSER ----\n",
    "ES_URL  = os.environ.get(\"ES_URL\",  \"http://localhost:9200\")\n",
    "ES_USER = os.environ.get(\"ES_USER\", \"elastic\")\n",
    "ES_PASS = os.environ.get(\"ES_PASS\", \"changeme\")\n",
    "\n",
    "MODEL_ID     = \".elser_model_2_linux-x86_64\"\n",
    "PIPELINE_ID  = \"elser_v2_pipeline\"\n",
    "TOKENS_FIELD = \"ml.tokens\"\n",
    "\n",
    "# ---- Excel source ----\n",
    "INDEX_NAME  = \"excel_elser_index\" \n",
    "FILE_PATH   = r\"C:\\Users\\dell\\elser-python\\long_distance_runners_record.xlsx\"  \n",
    "SHEET_NAME  = \"Sheet1\"  \n",
    "\n",
    "ID_COL       = \"Runner ID\"\n",
    "TITLE_COL    = \"Name\"\n",
    "EVENT_COL    = \"Event\"              \n",
    "COUNTRY_COL  = \"Country\"\n",
    "DATE_COL     = \"Date\"\n",
    "TIME_COL     = \"Time (HH:MM:SS)\"\n",
    "POSITION_COL = \"Position\"\n",
    "UPDATED_COL  = \"updated_at\"         \n",
    "\n",
    "# ---- Search ----\n",
    "QUERY_TEXT = \"fast half marathon runners from Kenya\"\n",
    "TOPK       = 5\n",
    "\n",
    "RUN_INGEST = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0ba15",
   "metadata": {},
   "source": [
    "## 2) Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_es(es, timeout_s=60):\n",
    "    deadline = time.time() + timeout_s\n",
    "    while time.time() < deadline:\n",
    "        try:\n",
    "            es.info()\n",
    "            return\n",
    "        except Exception:\n",
    "            time.sleep(1)\n",
    "    raise RuntimeError(\"Elasticsearch not responding\")\n",
    "\n",
    "def ensure_model_started(es):\n",
    "    try:\n",
    "        stats = es.ml.get_trained_models_stats(model_id=MODEL_ID)\n",
    "        tms = stats.get(\"trained_model_stats\", [])\n",
    "        if tms:\n",
    "            dstats = tms[0].get(\"deployment_stats\") or {}\n",
    "            if dstats.get(\"state\") == \"started\":\n",
    "                return\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        es.ml.start_trained_model_deployment(\n",
    "            model_id=MODEL_ID,\n",
    "            number_of_allocations=1,\n",
    "            threads_per_allocation=1,\n",
    "            queue_capacity=1024,\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def ensure_pipeline(es):\n",
    "    pipeline = {\n",
    "        \"processors\": [\n",
    "            {\n",
    "                \"inference\": {\n",
    "                    \"model_id\": MODEL_ID,\n",
    "                    \"input_output\": [\n",
    "                        {\"input_field\": \"content\", \"output_field\": TOKENS_FIELD}\n",
    "                    ],\n",
    "                    \"inference_config\": {\"text_expansion\": {}}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    es.ingest.put_pipeline(id=PIPELINE_ID, processors=pipeline[\"processors\"])\n",
    "\n",
    "def ensure_index(es, index: str, with_extra_fields=None):\n",
    "    if es.indices.exists(index=index):\n",
    "        return\n",
    "    props = {\n",
    "        \"content\": {\"type\": \"text\"},\n",
    "        \"ml\": {\"properties\": {\"tokens\": {\"type\": \"rank_features\"}}}\n",
    "    }\n",
    "    if with_extra_fields:\n",
    "        props.update(with_extra_fields)\n",
    "    es.indices.create(index=index, body={\"mappings\": {\"properties\": props}})\n",
    "\n",
    "def to_dt(v):\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "    if isinstance(v, datetime):\n",
    "        return v\n",
    "    try:\n",
    "        return dtparser.parse(str(v))\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26beb556",
   "metadata": {},
   "source": [
    "#### 3) Ingest Excel into ES (ELSER pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_excel(es, index: str, file_path: Path, sheet=None,\n",
    "                 id_col=\"id\", title_col=\"title\", event_col=\"body\",\n",
    "                 country_col=\"Country\", date_col=\"Date\", time_col=\"Time (HH:MM:SS)\",\n",
    "                 position_col=\"Position\", updated_col=\"updated_at\", batch=1000):\n",
    "    file_path = Path(file_path)\n",
    "    if file_path.suffix.lower() == \".xlsx\":\n",
    "        sheet_name = None\n",
    "        if sheet is not None:\n",
    "            try:\n",
    "                sheet_name = int(sheet)\n",
    "            except ValueError:\n",
    "                sheet_name = sheet\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name, engine=\"openpyxl\")\n",
    "    elif file_path.suffix.lower() == \".csv\":\n",
    "        df = pd.read_csv(file_path)\n",
    "    else:\n",
    "        raise SystemExit(\"Unsupported tabular format. Use .xlsx or .csv\")\n",
    "\n",
    "    cols = {c.lower().strip(): c for c in df.columns}\n",
    "    def col(name): return cols.get(name.lower(), name)\n",
    "\n",
    "    id_col       = col(id_col)\n",
    "    title_col    = col(title_col)\n",
    "    event_col    = col(event_col)\n",
    "    country_col  = col(country_col)\n",
    "    date_col     = col(date_col)\n",
    "    time_col     = col(time_col)\n",
    "    position_col = col(position_col)\n",
    "    updated_col  = col(updated_col)\n",
    "\n",
    "    missing = [c for c in [id_col, title_col] if c not in df.columns]\n",
    "    if missing:\n",
    "        raise SystemExit(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    ensure_index(es, index, with_extra_fields={\n",
    "        \"id\":        {\"type\": \"keyword\"},\n",
    "        \"title\":     {\"type\": \"text\"},\n",
    "        \"body\":      {\"type\": \"text\"},\n",
    "        \"country\":   {\"type\": \"keyword\"},\n",
    "        \"event\":     {\"type\": \"keyword\"},\n",
    "        \"date\":      {\"type\": \"date\"},\n",
    "        \"time_raw\":  {\"type\": \"keyword\"},\n",
    "        \"position\":  {\"type\": \"integer\"},\n",
    "        \"updated_at\":{\"type\": \"date\"}\n",
    "    })\n",
    "\n",
    "    actions = []\n",
    "    for _, row in df.iterrows():\n",
    "        rid      = row.get(id_col)\n",
    "        title    = row.get(title_col)\n",
    "        event    = row.get(event_col) if event_col in df.columns else None\n",
    "        country  = row.get(country_col) if country_col in df.columns else None\n",
    "        date_val = row.get(date_col) if date_col in df.columns else None\n",
    "        time_val = row.get(time_col) if time_col in df.columns else None\n",
    "        pos_val  = row.get(position_col) if position_col in df.columns else None\n",
    "        updated  = to_dt(row.get(updated_col)) if updated_col in df.columns else None\n",
    "\n",
    "        date_iso = None\n",
    "        if date_val is not None:\n",
    "            try:\n",
    "                date_iso = to_dt(date_val).date().isoformat()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        parts = []\n",
    "        if title:    parts.append(str(title))\n",
    "        if event:    parts.append(f\"Event: {event}\")\n",
    "        if country:  parts.append(f\"Country: {country}\")\n",
    "        if date_iso: parts.append(f\"Date: {date_iso}\")\n",
    "        if time_val not in (None, \"\"): parts.append(f\"Time: {time_val}\")\n",
    "        if pos_val not in (None, \"\"):  parts.append(f\"Position: {pos_val}\")\n",
    "        content = \". \".join(parts) if parts else (str(title) or \"\")\n",
    "\n",
    "        doc = {\n",
    "            \"id\":       rid,\n",
    "            \"title\":    title,\n",
    "            \"body\":     event,\n",
    "            \"event\":    event,\n",
    "            \"country\":  country,\n",
    "            \"date\":     date_iso,\n",
    "            \"time_raw\": str(time_val) if time_val is not None else None,\n",
    "            \"position\": int(pos_val) if str(pos_val).isdigit() else None,\n",
    "            \"content\":  content,\n",
    "        }\n",
    "        if updated is not None:\n",
    "            doc[\"updated_at\"] = updated.isoformat()\n",
    "\n",
    "        actions.append({\n",
    "            \"_op_type\": \"index\",\n",
    "            \"_index\": index,\n",
    "            \"_id\": str(rid) if rid is not None else None,\n",
    "            \"pipeline\": PIPELINE_ID,\n",
    "            \"_source\": doc\n",
    "        })\n",
    "\n",
    "    if not actions:\n",
    "        print(\"No rows to index.\"); return\n",
    "\n",
    "    print(f\"Indexing {len(actions)} rows from '{file_path.name}' → '{index}' via '{PIPELINE_ID}'...\")\n",
    "    success, fail = helpers.bulk(es, actions, stats_only=True, chunk_size=batch, request_timeout=120)\n",
    "    es.indices.refresh(index=index)\n",
    "    print(f\"Done. success={success}, failed={fail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35760ed",
   "metadata": {},
   "source": [
    "#### 4) Connect and (optionally) ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6170d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing 5 rows from 'long_distance_runners_record.xlsx' → 'excel_elser_index' via 'elser_v2_pipeline'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_13364\\212501029.py:100: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  success, fail = helpers.bulk(es, actions, stats_only=True, chunk_size=batch, request_timeout=120)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. success=5, failed=0\n"
     ]
    }
   ],
   "source": [
    "ES = Elasticsearch(ES_URL, basic_auth=(ES_USER, ES_PASS), request_timeout=120)\n",
    "\n",
    "wait_es(ES)\n",
    "ensure_model_started(ES)\n",
    "ensure_pipeline(ES)\n",
    "\n",
    "if RUN_INGEST:\n",
    "    ingest_excel(\n",
    "        ES, INDEX_NAME, FILE_PATH, SHEET_NAME,\n",
    "        id_col=ID_COL, title_col=TITLE_COL, event_col=EVENT_COL,\n",
    "        country_col=COUNTRY_COL, date_col=DATE_COL, time_col=TIME_COL,\n",
    "        position_col=POSITION_COL, updated_col=UPDATED_COL\n",
    "    )\n",
    "else:\n",
    "    print(\"RUN_INGEST=False — skipping ingest.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16e32b",
   "metadata": {},
   "source": [
    "#### 5) Run semantic search and save a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>name/title</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>snippet</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.450</td>\n",
       "      <td>5</td>\n",
       "      <td>David Lee</td>\n",
       "      <td>Half Marathon</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>David Lee. Event: Half Marathon. Country: Keny...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.424</td>\n",
       "      <td>2</td>\n",
       "      <td>Alice Smith</td>\n",
       "      <td>Half Marathon</td>\n",
       "      <td>UK</td>\n",
       "      <td>Alice Smith. Event: Half Marathon. Country: UK...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.521</td>\n",
       "      <td>4</td>\n",
       "      <td>Sophia Johnson</td>\n",
       "      <td>Marathon</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>Sophia Johnson. Event: Marathon. Country: Ethi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.928</td>\n",
       "      <td>1</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>Marathon</td>\n",
       "      <td>USA</td>\n",
       "      <td>John Doe. Event: Marathon. Country: USA. Date:...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.790</td>\n",
       "      <td>3</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>10K</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Michael Brown. Event: 10K. Country: Canada. Da...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score  id      name/title          event   country  \\\n",
       "0  24.450   5       David Lee  Half Marathon     Kenya   \n",
       "1  13.424   2     Alice Smith  Half Marathon        UK   \n",
       "2  10.521   4  Sophia Johnson       Marathon  Ethiopia   \n",
       "3   8.928   1        John Doe       Marathon       USA   \n",
       "4   3.790   3   Michael Brown            10K    Canada   \n",
       "\n",
       "                                             snippet updated_at  \n",
       "0  David Lee. Event: Half Marathon. Country: Keny...       None  \n",
       "1  Alice Smith. Event: Half Marathon. Country: UK...       None  \n",
       "2  Sophia Johnson. Event: Marathon. Country: Ethi...       None  \n",
       "3  John Doe. Event: Marathon. Country: USA. Date:...       None  \n",
       "4  Michael Brown. Event: 10K. Country: Canada. Da...       None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached results → C:\\Users\\dell\\Downloads\\elser_cached_results.json\n",
      "Saved HTML report → C:\\Users\\dell\\Downloads\\elser_search_report.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!doctype html>\n",
       "<html><head><meta charset=\"utf-8\"><title>ELSER Search Report</title>\n",
       "<style>\n",
       "body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; margin: 20px; }\n",
       "h1 { margin-bottom: 0; }\n",
       "small { color: #666; }\n",
       "table { border-collapse: collapse; width: 100%; margin-top: 12px; }\n",
       "th, td { border: 1px solid #ddd; padding: 8px; vertical-align: top; }\n",
       "th { background: #f4f4f4; }\n",
       "</style></head>\n",
       "<body>\n",
       "  <h1>ELSER Search Report</h1>\n",
       "  <small>Index: <b>excel_elser_index</b> • Query: <b>fast half marathon runners from Kenya</b> • Hits: <b>5</b></small>\n",
       "  <table>\n",
       "    <thead><tr><th>Score</th><th>Name/Title</th><th>Event</th><th>Country</th><th>Snippet</th></tr></thead>\n",
       "    <tbody><tr><td>24.45</td><td>David Lee</td><td>Half Marathon</td><td>Kenya</td><td>David Lee. Event: Half Marathon. Country: Kenya. Date: 2025-05-01. Time: 01:02:55. Position: 1</td></tr><tr><td>13.424</td><td>Alice Smith</td><td>Half Marathon</td><td>UK</td><td>Alice Smith. Event: Half Marathon. Country: UK. Date: 2025-02-10. Time: 01:05:30. Position: 2</td></tr><tr><td>10.521</td><td>Sophia Johnson</td><td>Marathon</td><td>Ethiopia</td><td>Sophia Johnson. Event: Marathon. Country: Ethiopia. Date: 2025-04-12. Time: 02:08:10. Position: 3</td></tr><tr><td>8.928</td><td>John Doe</td><td>Marathon</td><td>USA</td><td>John Doe. Event: Marathon. Country: USA. Date: 2025-01-15. Time: 02:12:45. Position: 5</td></tr><tr><td>3.79</td><td>Michael Brown</td><td>10K</td><td>Canada</td><td>Michael Brown. Event: 10K. Country: Canada. Date: 2025-03-05. Time: 00:32:15. Position: 1</td></tr></tbody>\n",
       "  </table>\n",
       "</body></html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "body = {\n",
    "    \"size\": TOPK,\n",
    "    \"query\": {\n",
    "        \"text_expansion\": {\n",
    "            TOKENS_FIELD: {\n",
    "                \"model_id\": MODEL_ID,\n",
    "                \"model_text\": QUERY_TEXT\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"_source\": [\"id\",\"title\",\"event\",\"country\",\"content\",\"updated_at\"]\n",
    "}\n",
    "res = ES.search(index=INDEX_NAME, body=body)\n",
    "\n",
    "hits = res.get(\"hits\", {}).get(\"hits\", [])\n",
    "rows = []\n",
    "for h in hits:\n",
    "    s = h[\"_source\"]\n",
    "    rows.append({\n",
    "        \"score\": round(h[\"_score\"], 3),\n",
    "        \"id\": s.get(\"id\"),\n",
    "        \"name/title\": s.get(\"title\"),\n",
    "        \"event\": s.get(\"event\"),\n",
    "        \"country\": s.get(\"country\"),\n",
    "        \"snippet\": (s.get(\"content\") or \"\")[:180].replace(\"\\n\",\" \"),\n",
    "        \"updated_at\": s.get(\"updated_at\")\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "display(df)\n",
    "\n",
    "cache_path = Path(\"elser_cached_results.json\")\n",
    "cache_path.write_text(json.dumps({\"query\": QUERY_TEXT, \"index\": INDEX_NAME, \"hits\": rows}, indent=2), encoding=\"utf-8\")\n",
    "print(f\"Cached results → {cache_path.resolve()}\")\n",
    "\n",
    "html_rows = \"\".join(\n",
    "    f\"<tr><td>{r['score']}</td><td>{r['name/title']}</td><td>{r['event']}</td><td>{r['country']}</td><td>{r['snippet']}</td></tr>\"\n",
    "    for r in rows\n",
    ")\n",
    "report_html = f\"\"\"\n",
    "<!doctype html>\n",
    "<html><head><meta charset=\"utf-8\"><title>ELSER Search Report</title>\n",
    "<style>\n",
    "body {{ font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; margin: 20px; }}\n",
    "h1 {{ margin-bottom: 0; }}\n",
    "small {{ color: #666; }}\n",
    "table {{ border-collapse: collapse; width: 100%; margin-top: 12px; }}\n",
    "th, td {{ border: 1px solid #ddd; padding: 8px; vertical-align: top; }}\n",
    "th {{ background: #f4f4f4; }}\n",
    "</style></head>\n",
    "<body>\n",
    "  <h1>ELSER Search Report</h1>\n",
    "  <small>Index: <b>{INDEX_NAME}</b> • Query: <b>{QUERY_TEXT}</b> • Hits: <b>{len(rows)}</b></small>\n",
    "  <table>\n",
    "    <thead><tr><th>Score</th><th>Name/Title</th><th>Event</th><th>Country</th><th>Snippet</th></tr></thead>\n",
    "    <tbody>{html_rows}</tbody>\n",
    "  </table>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "report_path = Path(\"elser_search_report.html\")\n",
    "report_path.write_text(report_html, encoding=\"utf-8\")\n",
    "print(f\"Saved HTML report → {report_path.resolve()}\")\n",
    "display(HTML(report_html))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
